#!/usr/bin/env python3
"""
Environment Fixer for Paperspace

This script addresses both CUDA environment issues and NumPy compatibility problems
often encountered on Paperspace notebooks.

Usage:
    python scripts/fix_environment.py
"""

import os
import sys
import subprocess
import argparse
import logging

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

def get_nvidia_info():
    """Get detailed NVIDIA GPU information using nvidia-smi."""
    try:
        result = subprocess.run(
            ["nvidia-smi"], 
            stdout=subprocess.PIPE, 
            stderr=subprocess.PIPE,
            text=True,
            check=False
        )
        
        if result.returncode == 0:
            return result.stdout
        else:
            return f"nvidia-smi returned error code {result.returncode}\n{result.stderr}"
    except Exception as e:
        return f"Error running nvidia-smi: {str(e)}"

def check_numpy():
    """Check NumPy version and compatibility."""
    try:
        import numpy as np
        numpy_version = np.__version__
        
        major_version = int(numpy_version.split('.')[0])
        if major_version >= 2:
            return {
                "version": numpy_version,
                "compatibility_issue": True,
                "fix_package": "numpy==1.24.3"
            }
        
        return {
            "version": numpy_version,
            "compatibility_issue": False
        }
    except ImportError:
        return {"error": "NumPy not installed"}
    except Exception as e:
        return {"error": f"Error checking NumPy: {str(e)}"}

def check_pytorch():
    """Check PyTorch installation and CUDA compatibility."""
    try:
        import torch
        
        info = {
            "torch_version": torch.__version__,
            "cuda_available": torch.cuda.is_available(),
            "cuda_device_count": torch.cuda.device_count() if torch.cuda.is_available() else 0,
        }
        
        if torch.cuda.is_available():
            info["cuda_version"] = torch.version.cuda
            info["device_name"] = torch.cuda.get_device_name(0)
            
            try:
                info["cudnn_version"] = torch.backends.cudnn.version()
                info["cudnn_enabled"] = torch.backends.cudnn.enabled
            except:
                info["cudnn_error"] = "Could not determine cuDNN info"
        
        return info
    except ImportError:
        return {"error": "PyTorch not installed"}
    except Exception as e:
        return {"error": f"Error checking PyTorch: {str(e)}"}

def get_recommended_env_vars(pytorch_info):
    """Get recommended environment variables based on the system and PyTorch info."""
    
    # Start with safe defaults
    recommended = {
        "CUDA_DEVICE_ORDER": "PCI_BUS_ID",
        "CUBLAS_WORKSPACE_CONFIG": ":4096:8",
        "PYTORCH_CUDA_ALLOC_CONF": "max_split_size_mb:128",
        "TORCH_USE_RTLD_GLOBAL": "YES",
        "PYTORCH_ALLOW_NET_FALLBACK": "1",
    }
    
    # Check if PyTorch can see CUDA
    if isinstance(pytorch_info, dict) and not pytorch_info.get("cuda_available", False):
        # If CUDA isn't available to PyTorch, check if NVIDIA driver is present
        nvidia_info = get_nvidia_info()
        if "NVIDIA-SMI" in nvidia_info and "Driver Version" in nvidia_info:
            # NVIDIA driver is present, but PyTorch can't see it
            # This suggests environment/library issues
            recommended.update({
                "LD_LIBRARY_PATH": "/usr/local/cuda/lib64:${LD_LIBRARY_PATH}",
                "TORCH_CUDA_ARCH_LIST": "8.0;8.6",
                "TORCH_NVCC_FLAGS": "-Xfatbin -compress-all"
            })
    
    # If using A6000 or other Ampere GPUs
    if isinstance(pytorch_info, dict) and pytorch_info.get("device_name", "").lower().find("a6000") >= 0:
        recommended["TORCH_CUDA_ARCH_LIST"] = "8.6"
    
    return recommended

def create_fix_script(recommended_vars, numpy_info):
    """Create a comprehensive fix script."""
    with open("fix_environment.sh", "w") as f:
        f.write("#!/bin/bash\n")
        f.write("# Environment fix script for CUDA and NumPy compatibility\n")
        f.write("# Generated by fix_environment.py\n\n")
        
        # CUDA environment variables
        f.write("# CUDA environment variables\n")
        for key, value in recommended_vars.items():
            # Quote values containing special characters or shell variables
            if any(c in value for c in ';- ') or '${' in value:
                f.write(f"export {key}=\"{value}\"\n")
            else:
                f.write(f"export {key}={value}\n")
        
        f.write("\n# Apply fixes\n")
        
        # NumPy fix
        if numpy_info.get("compatibility_issue", False):
            f.write("\n# Fix NumPy compatibility issue\n")
            f.write("echo \"Fixing NumPy compatibility issue...\"\n")
            numpy_package = numpy_info.get("fix_package", "numpy==1.24.3")
            f.write(f"pip install {numpy_package} -q\n")
            f.write("echo \"NumPy downgraded to compatible version\"\n")
        
        f.write("\necho \"Environment fixes applied successfully\"\n")
    
    os.chmod("fix_environment.sh", 0o755)
    logger.info("\nCreated fix_environment.sh with recommended fixes")
    logger.info("Run `source fix_environment.sh` to apply them to your current session")

def main():
    parser = argparse.ArgumentParser(description="Fix environment issues for Paperspace notebooks")
    parser.add_argument("--apply", action="store_true", help="Apply recommended fixes to current environment")
    parser.add_argument("--verbose", action="store_true", help="Show detailed diagnostic information")
    args = parser.parse_args()
    
    print("\n===== Environment Checker for Paperspace =====\n")
    
    # Check NumPy
    numpy_info = check_numpy()
    if "error" in numpy_info:
        print(f"NumPy: {numpy_info['error']}")
    else:
        print(f"NumPy: {numpy_info.get('version', 'unknown')}")
        if numpy_info.get('compatibility_issue', False):
            print("⚠️ NumPy compatibility issue detected! This may cause PyTorch to crash or behave unexpectedly.")
    
    # Check PyTorch
    pytorch_info = check_pytorch()
    if "error" in pytorch_info:
        print(f"PyTorch: {pytorch_info['error']}")
    else:
        print(f"PyTorch: {pytorch_info.get('torch_version', 'unknown')}")
        print(f"CUDA available: {pytorch_info.get('cuda_available', False)}")
        if pytorch_info.get('cuda_available', False):
            print(f"CUDA version: {pytorch_info.get('cuda_version', 'unknown')}")
            print(f"GPU: {pytorch_info.get('device_name', 'unknown')}")
            print(f"cuDNN version: {pytorch_info.get('cudnn_version', 'unknown')}")
    
    # Get recommended environment variables
    recommended_vars = get_recommended_env_vars(pytorch_info)
    
    print("\n----- Recommended Environment Variables -----")
    for key, value in recommended_vars.items():
        print(f"export {key}={value}")
    
    # Create fix script
    create_fix_script(recommended_vars, numpy_info)
    
    # Apply the recommendations if requested
    if args.apply:
        print("\nApplying recommended environment variables...")
        for key, value in recommended_vars.items():
            os.environ[key] = value
            print(f"Set {key}={value}")
        
        # Fix NumPy if needed
        if numpy_info.get("compatibility_issue", False) and numpy_info.get("fix_package"):
            print("\nFixing NumPy compatibility issue...")
            numpy_package = numpy_info.get("fix_package", "numpy==1.24.3")
            subprocess.run(f"pip install {numpy_package}", shell=True, check=False)
            print("NumPy fixed!")
        
        print("\nAttempting to import PyTorch again...")
        try:
            import torch
            print(f"PyTorch: {torch.__version__}")
            print(f"CUDA available: {torch.cuda.is_available()}")
            if torch.cuda.is_available():
                print(f"CUDA version: {torch.version.cuda}")
                print(f"GPU: {torch.cuda.get_device_name(0)}")
        except Exception as e:
            print(f"Error importing PyTorch: {e}")
    
    print("\nDone!")

if __name__ == "__main__":
    main() 
{
  "model": {
    "base_model": "google/flan-ul2",
    "use_unsloth": true,
    "use_4bit": true,
    "use_nested_quant": true,
    "bnb_4bit_compute_dtype": "float16",
    "use_gradient_checkpointing": true,
    "xformers_attention": true
  },
  "peft": {
    "lora_alpha": 16,
    "lora_dropout": 0.05,
    "r": 32,
    "bias": "none",
    "task_type": "CAUSAL_LM",
    "target_modules": [
      "q_proj",
      "k_proj",
      "v_proj",
      "o_proj",
      "gate_proj",
      "up_proj",
      "down_proj"
    ]
  },
  "training": {
    "output_dir": "models/flan-ul2-finetune",
    "num_train_epochs": 3,
    "per_device_train_batch_size": 2,
    "per_device_eval_batch_size": 2,
    "gradient_accumulation_steps": 16,
    "evaluation_strategy": "steps",
    "eval_steps": 200,
    "save_strategy": "steps",
    "save_steps": 500,
    "save_total_limit": 3,
    "learning_rate": 1e-4,
    "weight_decay": 0.01,
    "warmup_ratio": 0.03,
    "lr_scheduler_type": "cosine",
    "logging_steps": 50,
    "report_to": ["wandb", "tensorboard"],
    "seed": 42,
    "fp16": true,
    "bf16": false,
    "push_to_hub": false,
    "use_deepspeed": true,
    "deepspeed": {
      "zero_stage": 3,
      "offload_optimizer": {
        "device": "cpu"
      },
      "offload_param": {
        "device": "cpu"
      },
      "gradient_clipping": 1.0
    },
    "max_grad_norm": 1.0,
    "dataloader_num_workers": 8,
    "group_by_length": true,
    "optim": "adamw_torch",
    "shuffle_dataset": true,
    "max_steps": -1,
    "ddp_find_unused_parameters": false,
    "torch_compile": true
  },
  "dataset": {
    "max_length": 1024,
    "dataset_weights": {
      "openassistant": 2.0,
      "gpteacher_general": 1.5,
      "pile": 1.0,
      "synthetic_persona": 1.5,
      "writingprompts": 2.0
    },
    "train_size": 0.9,
    "val_size": 0.05,
    "test_size": 0.05,
    "streaming": true,
    "use_cache": false,
    "interleave_prob": 0.5,
    "max_samples": {
      "openassistant": 30000,
      "gpteacher_general": 30000,
      "pile": 50000,
      "synthetic_persona": 20000,
      "writingprompts": 25000
    }
  },
  "hardware": {
    "gpu": "A6000",
    "vram_gb": 48,
    "ram_gb": 45,
    "cpu_cores": 8
  },
  "google_drive": {
    "use_drive": true,
    "base_dir": "FlanUL2Text"
  }
}

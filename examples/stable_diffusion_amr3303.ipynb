{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using Fine-Tuned Stable Diffusion Model (amr3303)\n",
        "\n",
        "This notebook demonstrates how to use the fine-tuned Stable Diffusion model from amr3303 to generate high-quality images. We'll explore different parameters and techniques to achieve optimal results similar to checkpoint generations.\n",
        "\n",
        "## Setup and Installation\n",
        "\n",
        "First, let's install the necessary dependencies if they're not already installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment and run if you need to install dependencies\n",
        "# !pip install diffusers transformers accelerate safetensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the Model\n",
        "\n",
        "Now, let's load the fine-tuned Stable Diffusion model from Hugging Face Hub. You'll need to authenticate with your Hugging Face token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from diffusers import DiffusionPipeline\n",
        "import torch\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Login to Hugging Face Hub\n",
        "# Replace with your own token if needed\n",
        "login()\n",
        "\n",
        "# Load the model and move it to GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the fine-tuned model\n",
        "pipe = DiffusionPipeline.from_pretrained(\"amr3303/fine-tuned-sd-amr\", torch_dtype=torch.float16)\n",
        "pipe = pipe.to(device)\n",
        "\n",
        "# Enable memory efficient attention if using PyTorch 2.0\n",
        "if hasattr(pipe, \"enable_xformers_memory_efficient_attention\"):\n",
        "    pipe.enable_xformers_memory_efficient_attention()\n",
        "elif hasattr(pipe, \"enable_attention_slicing\"):\n",
        "    pipe.enable_attention_slicing()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic Image Generation\n",
        "\n",
        "Let's start with a basic image generation using default parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_images(images, titles=None, cols=3, figsize=(15, 10)):\n",
        "    \"\"\"Display a list of images in a grid.\"\"\"\n",
        "    rows = (len(images) + cols - 1) // cols\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    for i, image in enumerate(images):\n",
        "        ax = fig.add_subplot(rows, cols, i + 1)\n",
        "        if titles is not None:\n",
        "            ax.set_title(titles[i])\n",
        "        plt.imshow(image)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Basic prompt\n",
        "prompt = \"A beautiful portrait of a woman with long hair, detailed features, high quality, photorealistic\"\n",
        "\n",
        "# Generate image with default parameters\n",
        "image = pipe(prompt).images[0]\n",
        "\n",
        "# Display the image\n",
        "display_images([image], [\"Basic Generation\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimizing Generation Parameters\n",
        "\n",
        "Now, let's experiment with different parameters to achieve better results:\n",
        "\n",
        "1. **Guidance Scale**: Controls how closely the image follows the prompt (higher values = more adherence)\n",
        "2. **Number of Steps**: More steps generally produce better quality but take longer\n",
        "3. **Scheduler**: Different schedulers can produce different results\n",
        "4. **Seed**: Setting a seed allows for reproducible results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from diffusers import DPMSolverMultistepScheduler, EulerDiscreteScheduler, EulerAncestralDiscreteScheduler\n",
        "\n",
        "# Test different guidance scales\n",
        "guidance_scales = [7.0, 8.5, 10.0]\n",
        "images_guidance = []\n",
        "titles_guidance = []\n",
        "\n",
        "# Set a seed for reproducibility\n",
        "generator = torch.Generator(device=device).manual_seed(42)\n",
        "\n",
        "for guidance_scale in guidance_scales:\n",
        "    image = pipe(\n",
        "        prompt,\n",
        "        guidance_scale=guidance_scale,\n",
        "        num_inference_steps=50,  # Increased steps for better quality\n",
        "        generator=generator,\n",
        "    ).images[0]\n",
        "    \n",
        "    images_guidance.append(image)\n",
        "    titles_guidance.append(f\"Guidance Scale: {guidance_scale}\")\n",
        "\n",
        "# Display the results\n",
        "display_images(images_guidance, titles_guidance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test different schedulers\n",
        "schedulers = [\n",
        "    (\"DPM++ 2M\", DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)),\n",
        "    (\"Euler\", EulerDiscreteScheduler.from_config(pipe.scheduler.config)),\n",
        "    (\"Euler a\", EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config))\n",
        "]\n",
        "\n",
        "images_scheduler = []\n",
        "titles_scheduler = []\n",
        "\n",
        "# Use the best guidance scale from previous experiment\n",
        "best_guidance_scale = 8.5  # Adjust based on your preference from previous results\n",
        "\n",
        "for name, scheduler in schedulers:\n",
        "    # Update the scheduler\n",
        "    pipe.scheduler = scheduler\n",
        "    \n",
        "    # Generate image\n",
        "    image = pipe(\n",
        "        prompt,\n",
        "        guidance_scale=best_guidance_scale,\n",
        "        num_inference_steps=50,\n",
        "        generator=torch.Generator(device=device).manual_seed(42),\n",
        "    ).images[0]\n",
        "    \n",
        "    images_scheduler.append(image)\n",
        "    titles_scheduler.append(f\"Scheduler: {name}\")\n",
        "\n",
        "# Display the results\n",
        "display_images(images_scheduler, titles_scheduler)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced Prompt Engineering\n",
        "\n",
        "The quality of the generated images heavily depends on the prompts. Let's experiment with different prompt techniques to get the best results from this model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select the best scheduler based on previous results\n",
        "# Adjust this based on your preference from the previous experiment\n",
        "best_scheduler_name = \"DPM++ 2M\"  # Example, change as needed\n",
        "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "# Test different prompt techniques\n",
        "prompts = [\n",
        "    \"A beautiful portrait of a woman with long hair\",  # Basic prompt\n",
        "    \"A beautiful portrait of a woman with long hair, detailed features, high quality, photorealistic, 8k, professional photography\",  # Detailed prompt with quality descriptors\n",
        "    \"A beautiful portrait of a woman with long hair, detailed features, high quality, photorealistic, 8k, professional photography, soft lighting, shallow depth of field, bokeh, award-winning, masterpiece\",  # Advanced prompt with artistic descriptors\n",
        "]\n",
        "\n",
        "images_prompt = []\n",
        "titles_prompt = []\n",
        "\n",
        "for i, prompt in enumerate(prompts):\n",
        "    image = pipe(\n",
        "        prompt,\n",
        "        guidance_scale=best_guidance_scale,\n",
        "        num_inference_steps=50,\n",
        "        generator=torch.Generator(device=device).manual_seed(42),\n",
        "    ).images[0]\n",
        "    \n",
        "    images_prompt.append(image)\n",
        "    titles_prompt.append(f\"Prompt Technique {i+1}\")\n",
        "\n",
        "# Display the results\n",
        "display_images(images_prompt, titles_prompt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Negative Prompts\n",
        "\n",
        "Negative prompts tell the model what to avoid in the generated image. This can significantly improve the quality of the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Best prompt from previous experiment\n",
        "best_prompt = \"A beautiful portrait of a woman with long hair, detailed features, high quality, photorealistic, 8k, professional photography, soft lighting, shallow depth of field, bokeh, award-winning, masterpiece\"\n",
        "\n",
        "# Test different negative prompts\n",
        "negative_prompts = [\n",
        "    None,  # No negative prompt\n",
        "    \"blurry, low quality, distorted, deformed features\",  # Basic negative prompt\n",
        "    \"blurry, low quality, distorted, deformed features, bad anatomy, disfigured, poorly drawn face, mutation, mutated, extra limb, ugly, poorly drawn hands, missing limb, floating limbs, disconnected limbs, malformed hands, out of focus, long neck, long body, text, watermark, signature\",  # Comprehensive negative prompt\n",
        "]\n",
        "\n",
        "images_negative = []\n",
        "titles_negative = []\n",
        "\n",
        "for i, negative_prompt in enumerate(negative_prompts):\n",
        "    image = pipe(\n",
        "        best_prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        guidance_scale=best_guidance_scale,\n",
        "        num_inference_steps=50,\n",
        "        generator=torch.Generator(device=device).manual_seed(42),\n",
        "    ).images[0]\n",
        "    \n",
        "    images_negative.append(image)\n",
        "    titles_negative.append(f\"Negative Prompt {i+1}\")\n",
        "\n",
        "# Display the results\n",
        "display_images(images_negative, titles_negative)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimized Generation\n",
        "\n",
        "Now, let's combine all the best parameters and techniques to generate the highest quality images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimal parameters based on previous experiments\n",
        "optimal_prompt = \"A beautiful portrait of a woman with long hair, detailed features, high quality, photorealistic, 8k, professional photography, soft lighting, shallow depth of field, bokeh, award-winning, masterpiece\"\n",
        "\n",
        "optimal_negative_prompt = \"blurry, low quality, distorted, deformed features, bad anatomy, disfigured, poorly drawn face, mutation, mutated, extra limb, ugly, poorly drawn hands, missing limb, floating limbs, disconnected limbs, malformed hands, out of focus, long neck, long body, text, watermark, signature\"\n",
        "\n",
        "# Generate multiple images with different seeds\n",
        "seeds = [42, 123, 456, 789, 1024]\n",
        "images_optimal = []\n",
        "titles_optimal = []\n",
        "\n",
        "for seed in seeds:\n",
        "    image = pipe(\n",
        "        optimal_prompt,\n",
        "        negative_prompt=optimal_negative_prompt,\n",
        "        guidance_scale=best_guidance_scale,\n",
        "        num_inference_steps=50,\n",
        "        generator=torch.Generator(device=device).manual_seed(seed),\n",
        "    ).images[0]\n",
        "    \n",
        "    images_optimal.append(image)\n",
        "    titles_optimal.append(f\"Seed: {seed}\")\n",
        "\n",
        "# Display the results\n",
        "display_images(images_optimal, titles_optimal, cols=2, figsize=(12, 15))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving Generated Images\n",
        "\n",
        "Let's save our best generated images to disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "output_dir = \"generated_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Save the optimal images\n",
        "for i, image in enumerate(images_optimal):\n",
        "    image_path = os.path.join(output_dir, f\"optimal_image_{i+1}.png\")\n",
        "    image.save(image_path)\n",
        "    print(f\"Saved image to {image_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we've explored how to use the fine-tuned Stable Diffusion model from amr3303 to generate high-quality images. We've experimented with different parameters and techniques to achieve optimal results:\n",
        "\n",
        "1. **Best Parameters**:\n",
        "   - Guidance Scale: 8.5 (adjust based on your preference)\n",
        "   - Number of Steps: 50\n",
        "   - Scheduler: DPM++ 2M (adjust based on your preference)\n",
        "\n",
        "2. **Prompt Engineering**:\n",
        "   - Use detailed prompts with quality descriptors\n",
        "   - Include artistic elements like lighting and depth of field\n",
        "   - Use comprehensive negative prompts to avoid common issues\n",
        "\n",
        "3. **Tips for Best Results**:\n",
        "   - Experiment with different seeds to find the best results\n",
        "   - Adjust guidance scale based on your specific prompt\n",
        "   - Use negative prompts to avoid common artifacts\n",
        "\n",
        "This model produces excellent results when properly prompted and configured. Feel free to experiment with different prompts and parameters to achieve your desired output."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
